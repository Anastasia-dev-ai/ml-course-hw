В ходе задания мы написали руками алгоритм для построения линейной регресии на данных о стоимости домов.
Угол наклона прямой подбирается с помощью градиентного спуска, поэтому нужно было вычислить значение градиентов для функции ошибок типа MSE и MAE с L2 и L1
регуляризацией
Был подобран оптимальный вектор w для ошибки MSE с L2 регуляризацией и отрисован результат на одном графике с данными и срешением от sklearn
На графике мы видим, что прямые для рукописного алгоритма поиска w и sklearn очень близки, но не совпадают полностью.
Могу предролижить, что есть 2 причины для этого:
1) Наш алгоритм не имеет bias term, что означает что если данные имеют смещение, то мы их не сможем аппороксимировать.
2) В реализацию Ridge мы передавали alfa=0.5 (коэф регуляризации), а в самописной версии alfa=1, то есть мы больше штрафуем за большие по модулю веса